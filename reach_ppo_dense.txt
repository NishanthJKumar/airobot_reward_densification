[32m[INFO][0m[2022-05-03 03:13:40]: [32mAlogrithm type:<class 'easyrl.configs.ppo_config.PPOConfig'>[0m
[32m[INFO][0m[2022-05-03 03:13:40]: [32mCreating 1 environments.[0m
pybullet build time: Mar 26 2022 03:00:15
[32m[INFO][0m[2022-05-03 03:13:40]: [32mLoad in OpenGL![0m
EGL device choice: -1 of 3.
argv[0]=
Loaded EGL 1.5 after reload.
GL_VENDOR=NVIDIA Corporation
GL_RENDERER=NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2
GL_VERSION=4.6.0 NVIDIA 470.103.01
GL_SHADING_LANGUAGE_VERSION=4.60 NVIDIA
Version = 4.6.0 NVIDIA 470.103.01
Vendor = NVIDIA Corporation
Renderer = NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2
b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
ee_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
baseb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
tool0b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
ee_tipINFO     planner time limit: None
INFO     planner memory limit: None

INFO     Running translator.
INFO     translator stdin: None
INFO     translator time limit: None
INFO     translator memory limit: None
INFO     translator command line string: /home/wbm3/anaconda3/envs/6484_dqn/bin/python /home/wbm3/Documents/GitHub/downward/builds/release/bin/translate/translate.py /home/wbm3/Documents/GitHub/airobot_reward_densification/envs/reaching_env/single_subgoal/goal-subgoal-domain.pddl /home/wbm3/Documents/GitHub/airobot_reward_densification/envs/reaching_env/single_subgoal/goal-subgoal-problem.pddl --sas-file output.sas
Parsing...
Parsing: [0.000s CPU, 0.000s wall-clock]
Normalizing task... [0.000s CPU, 0.000s wall-clock]
Instantiating...
Generating Datalog program... [0.000s CPU, 0.000s wall-clock]
Normalizing Datalog program...
Normalizing Datalog program: [0.000s CPU, 0.000s wall-clock]
Preparing model... [0.000s CPU, 0.000s wall-clock]
Generated 10 rules.
Computing model... [0.000s CPU, 0.000s wall-clock]
17 relevant atoms
8 auxiliary atoms
25 final queue length
27 total queue pushes
Completing instantiation... [0.000s CPU, 0.000s wall-clock]
Instantiating: [0.000s CPU, 0.001s wall-clock]
Computing fact groups...
Finding invariants...
3 initial candidates
Finding invariants: [0.000s CPU, 0.000s wall-clock]
Checking invariant weight... [0.000s CPU, 0.000s wall-clock]
Instantiating groups... [0.000s CPU, 0.000s wall-clock]
Collecting mutex groups... [0.000s CPU, 0.000s wall-clock]
Choosing groups...
2 uncovered facts
Choosing groups: [0.000s CPU, 0.000s wall-clock]
Building translation key... [0.000s CPU, 0.000s wall-clock]
Computing fact groups: [0.000s CPU, 0.000s wall-clock]
Building STRIPS to SAS dictionary... [0.000s CPU, 0.000s wall-clock]
Building dictionary for full mutex groups... [0.000s CPU, 0.000s wall-clock]
Building mutex information...
Building mutex information: [0.000s CPU, 0.000s wall-clock]
Translating task...
Processing axioms...
Simplifying axioms... [0.000s CPU, 0.000s wall-clock]
Translator axioms removed by simplifying: 0
Computing negative axioms... [0.000s CPU, 0.000s wall-clock]
Processing axioms: [0.000s CPU, 0.000s wall-clock]
Translating task: [0.000s CPU, 0.000s wall-clock]
1 effect conditions simplified
0 implied preconditions added
Detecting unreachable propositions...
0 operators removed
0 axioms removed
0 propositions removed
Detecting unreachable propositions: [0.000s CPU, 0.000s wall-clock]
Reordering and filtering variables...
2 of 2 variables necessary.
0 of 0 mutex groups necessary.
2 of 2 operators necessary.
0 of 0 axiom rules necessary.
Reordering and filtering variables: [0.000s CPU, 0.000s wall-clock]
Translator variables: 2
Translator derived variables: 0
Translator facts: 4
Translator goal facts: 1
Translator mutex groups: 0
Translator total mutex groups size: 0
Translator operators: 2
Translator axioms: 0
Translator task size: 15
Translator peak memory: 29696 KB
Writing output... [0.000s CPU, 0.000s wall-clock]
Done! [0.000s CPU, 0.002s wall-clock]
translate exit code: 0

INFO     Running search (release).
INFO     search stdin: output.sas
INFO     search time limit: None
INFO     search memory limit: None
INFO     search command line string: /home/wbm3/Documents/GitHub/downward/builds/release/bin/downward --if-unit-cost --evaluator 'hlm=lmcount(lm_reasonable_orders_hps(lm_rhw()),pref=true)' --evaluator 'hff=ff()' --search 'iterated([lazy_greedy([hff,hlm],preferred=[hff,hlm]),lazy_wastar([hff,hlm],preferred=[hff,hlm],w=5),lazy_wastar([hff,hlm],preferred=[hff,hlm],w=3),lazy_wastar([hff,hlm],preferred=[hff,hlm],w=2),lazy_wastar([hff,hlm],preferred=[hff,hlm],w=1)],repeat_last=true,continue_on_fail=true)' --if-non-unit-cost --evaluator 'hlm1=lmcount(lm_reasonable_orders_hps(lm_rhw()),transform=adapt_costs(one),pref=true)' --evaluator 'hff1=ff(transform=adapt_costs(one))' --evaluator 'hlm2=lmcount(lm_reasonable_orders_hps(lm_rhw()),transform=adapt_costs(plusone),pref=true)' --evaluator 'hff2=ff(transform=adapt_costs(plusone))' --search 'iterated([lazy_greedy([hff1,hlm1],preferred=[hff1,hlm1],cost_type=one,reopen_closed=false),lazy_greedy([hff2,hlm2],preferred=[hff2,hlm2],reopen_closed=false),lazy_wastar([hff2,hlm2],preferred=[hff2,hlm2],w=5),lazy_wastar([hff2,hlm2],preferred=[hff2,hlm2],w=3),lazy_wastar([hff2,hlm2],preferred=[hff2,hlm2],w=2),lazy_wastar([hff2,hlm2],preferred=[hff2,hlm2],w=1)],repeat_last=true,continue_on_fail=true)' --always --internal-plan-file sas_plan < output.sas
[t=1.32e-05s, 13696 KB] reading input...
[t=7.231e-05s, 13696 KB] done reading input!
[t=0.00076723s, 14084 KB] Initializing landmark count heuristic...
[t=0.00078883s, 14084 KB] Generating landmark graph...
[t=0.00080063s, 14084 KB] Building a landmark graph with reasonable orders.
[t=0.00080931s, 14084 KB] Initializing Exploration...
[t=0.00081883s, 14084 KB] Generating landmarks using the RPG/SAS+ approach
[t=0.00084394s, 14084 KB] Removed 0 reasonable or obedient reasonable orders
[t=0.00085297s, 14084 KB] Landmarks generation time: 5.108e-05s
[t=0.00086093s, 14084 KB] Discovered 4 landmarks, of which 0 are disjunctive and 0 are conjunctive.
[t=0.00086776s, 14084 KB] 3 edges
[t=0.00087498s, 14084 KB] approx. reasonable orders
[t=0.00088332s, 14084 KB] approx. obedient reasonable orders
[t=0.00089063s, 14084 KB] Removed 0 reasonable or obedient reasonable orders
[t=0.00089741s, 14084 KB] Landmarks generation time: 0.00010438s
[t=0.00090473s, 14084 KB] Discovered 4 landmarks, of which 0 are disjunctive and 0 are conjunctive.
[t=0.00091122s, 14084 KB] 3 edges
[t=0.00091784s, 14084 KB] Landmark graph generation time: 0.00013497s
[t=0.00092478s, 14084 KB] Landmark graph contains 4 landmarks, of which 0 are disjunctive and 0 are conjunctive.
[t=0.00093132s, 14084 KB] Landmark graph contains 3 orderings.
[t=0.00095554s, 14084 KB] Simplifying 3 unary operators... done! [3 unary operators]
[t=0.00096788s, 14084 KB] time to simplify: 1.928e-05s
[t=0.00097606s, 14084 KB] Initializing additive heuristic...
[t=0.00098285s, 14084 KB] Initializing FF heuristic...
[t=0.00102952s, 14084 KB] Building successor generator...done!
[t=0.00105506s, 14084 KB] peak memory difference for successor generator creation: 0 KB
[t=0.00106188s, 14084 KB] time for successor generation creation: 2.37e-06s
[t=0.00107008s, 14084 KB] Variables: 2
[t=0.00107685s, 14084 KB] FactPairs: 4
[t=0.00108374s, 14084 KB] Bytes per state: 4
[t=0.00123457s, 14348 KB] Building successor generator...done!
[t=0.00127683s, 14348 KB] peak memory difference for successor generator creation: 0 KB
[t=0.00128643s, 14348 KB] time for successor generation creation: 2.5e-07s
[t=0.00129478s, 14348 KB] Variables: 2
[t=0.00130167s, 14348 KB] FactPairs: 4
[t=0.00130824s, 14348 KB] Bytes per state: 4
[t=0.00132215s, 14348 KB] Starting search: lazy_greedy(list(hff, hlm), preferred = list(hff, hlm))
[t=0.00133176s, 14348 KB] Conducting lazy best first search, (real) bound = 2147483647
[t=0.00134168s, 14348 KB] 2 initial landmarks, 1 goal landmarks
[t=0.0013594s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00136818s, 14348 KB] New best heuristic value for ff: 2
[t=0.00137533s, 14348 KB] g=0, 1 evaluated, 0 expanded
[t=0.00138422s, 14348 KB] Initial heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00139128s, 14348 KB] Initial heuristic value for ff: 2
[t=0.00140196s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 1
[t=0.00140974s, 14348 KB] New best heuristic value for ff: 1
[t=0.00141648s, 14348 KB] g=1, 2 evaluated, 1 expanded
[t=0.0014259s, 14348 KB] Solution found!
[t=0.00143356s, 14348 KB] Actual search time: 8.895e-05s
move-to-subgoal claw subgoal (1)
move-to-goal claw subgoal goal (1)
[t=0.00145996s, 14348 KB] Plan length: 2 step(s).
[t=0.00146885s, 14348 KB] Plan cost: 2
[t=0.00147618s, 14348 KB] Expanded 2 state(s).
[t=0.00148282s, 14348 KB] Reopened 0 state(s).
[t=0.00148946s, 14348 KB] Evaluated 3 state(s).
[t=0.00149605s, 14348 KB] Evaluations: 6
[t=0.00150261s, 14348 KB] Generated 2 state(s).
[t=0.00150958s, 14348 KB] Dead ends: 0 state(s).
[t=0.00151617s, 14348 KB] Number of registered states: 3
[t=0.00152297s, 14348 KB] Int hash set load factor: 3/4 = 0.75
[t=0.00153001s, 14348 KB] Int hash set resizes: 2
[t=0.0015366s, 14348 KB] Best solution cost so far: 2
[t=0.00154305s, 14348 KB] Solution found - keep searching
[t=0.00157877s, 14348 KB] Building successor generator...done!
[t=0.00160089s, 14348 KB] peak memory difference for successor generator creation: 0 KB
[t=0.00160794s, 14348 KB] time for successor generation creation: 2.1e-07s
[t=0.00161552s, 14348 KB] Variables: 2
[t=0.00162226s, 14348 KB] FactPairs: 4
[t=0.0016288s, 14348 KB] Bytes per state: 4
[t=0.00164517s, 14348 KB] Starting search: lazy_wastar(list(hff, hlm), preferred = list(hff, hlm), w = 5)
[t=0.00165473s, 14348 KB] Conducting lazy best first search, (real) bound = 2
[t=0.00166374s, 14348 KB] 2 initial landmarks, 1 goal landmarks
[t=0.00167575s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00168347s, 14348 KB] New best heuristic value for ff: 2
[t=0.00169045s, 14348 KB] g=0, 1 evaluated, 0 expanded
[t=0.00169921s, 14348 KB] Initial heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00170617s, 14348 KB] Initial heuristic value for ff: 2
[t=0.00171627s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 1
[t=0.00172422s, 14348 KB] New best heuristic value for ff: 1
[t=0.00173144s, 14348 KB] g=1, 2 evaluated, 1 expanded
[t=0.00173953s, 14348 KB] Completely explored state space -- no solution!
[t=0.0017464s, 14348 KB] Actual search time: 8.11e-05s
[t=0.00175362s, 14348 KB] Expanded 2 state(s).
[t=0.00176048s, 14348 KB] Reopened 0 state(s).
[t=0.00176703s, 14348 KB] Evaluated 2 state(s).
[t=0.00177408s, 14348 KB] Evaluations: 4
[t=0.00178058s, 14348 KB] Generated 2 state(s).
[t=0.00178694s, 14348 KB] Dead ends: 0 state(s).
[t=0.00179349s, 14348 KB] Number of registered states: 2
[t=0.00180005s, 14348 KB] Int hash set load factor: 2/2 = 1
[t=0.00180702s, 14348 KB] Int hash set resizes: 1
[t=0.00181364s, 14348 KB] Best solution cost so far: 2
[t=0.0018202s, 14348 KB] No solution found - keep searching
[t=0.00185197s, 14348 KB] Building successor generator...done!
[t=0.00187374s, 14348 KB] peak memory difference for successor generator creation: 0 KB
[t=0.00188051s, 14348 KB] time for successor generation creation: 2.2e-07s
[t=0.00188801s, 14348 KB] Variables: 2
[t=0.00189471s, 14348 KB] FactPairs: 4
[t=0.00190385s, 14348 KB] Bytes per state: 4
[t=0.00191478s, 14348 KB] Starting search: lazy_wastar(list(hff, hlm), preferred = list(hff, hlm), w = 3)
[t=0.00192318s, 14348 KB] Conducting lazy best first search, (real) bound = 2
[t=0.00193149s, 14348 KB] 2 initial landmarks, 1 goal landmarks
[t=0.00194283s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00195087s, 14348 KB] New best heuristic value for ff: 2
[t=0.00195797s, 14348 KB] g=0, 1 evaluated, 0 expanded
[t=0.00196653s, 14348 KB] Initial heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00197358s, 14348 KB] Initial heuristic value for ff: 2
[t=0.00198351s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 1
[t=0.00199116s, 14348 KB] New best heuristic value for ff: 1
[t=0.00199802s, 14348 KB] g=1, 2 evaluated, 1 expanded
[t=0.00201065s, 14348 KB] Completely explored state space -- no solution!
[t=0.00201812s, 14348 KB] Actual search time: 8.529e-05s
[t=0.0020254s, 14348 KB] Expanded 2 state(s).
[t=0.00203198s, 14348 KB] Reopened 0 state(s).
[t=0.00203847s, 14348 KB] Evaluated 2 state(s).
[t=0.00204493s, 14348 KB] Evaluations: 4
[t=0.0020516s, 14348 KB] Generated 2 state(s).
[t=0.00205819s, 14348 KB] Dead ends: 0 state(s).
[t=0.00206474s, 14348 KB] Number of registered states: 2
[t=0.00207272s, 14348 KB] Int hash set load factor: 2/2 = 1
[t=0.00208371s, 14348 KB] Int hash set resizes: 1
[t=0.00209019s, 14348 KB] Best solution cost so far: 2
[t=0.00209668s, 14348 KB] No solution found - keep searching
[t=0.00212727s, 14348 KB] Building successor generator...done!
[t=0.00214905s, 14348 KB] peak memory difference for successor generator creation: 0 KB
[t=0.00215635s, 14348 KB] time for successor generation creation: 2.2e-07s
[t=0.00216395s, 14348 KB] Variables: 2
[t=0.00217085s, 14348 KB] FactPairs: 4
[t=0.00217741s, 14348 KB] Bytes per state: 4
[t=0.00218749s, 14348 KB] Starting search: lazy_wastar(list(hff, hlm), preferred = list(hff, hlm), w = 2)
[t=0.00219579s, 14348 KB] Conducting lazy best first search, (real) bound = 2
[t=0.00220395s, 14348 KB] 2 initial landmarks, 1 goal landmarks
[t=0.00221487s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00222205s, 14348 KB] New best heuristic value for ff: 2
[t=0.00222877s, 14348 KB] g=0, 1 evaluated, 0 expanded
[t=0.00223705s, 14348 KB] Initial heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.0022439s, 14348 KB] Initial heuristic value for ff: 2
[t=0.00225415s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 1
[t=0.00226853s, 14348 KB] New best heuristic value for ff: 1
[t=0.0022825s, 14348 KB] g=1, 2 evaluated, 1 expanded
[t=0.00229474s, 14348 KB] Completely explored state space -- no solution!
[t=0.00230303s, 14348 KB] Actual search time: 9.821e-05s
[t=0.00231075s, 14348 KB] Expanded 2 state(s).
[t=0.00231771s, 14348 KB] Reopened 0 state(s).
[t=0.00232626s, 14348 KB] Evaluated 2 state(s).
[t=0.00233287s, 14348 KB] Evaluations: 4
[t=0.00233944s, 14348 KB] Generated 2 state(s).
[t=0.00234598s, 14348 KB] Dead ends: 0 state(s).
[t=0.0023526s, 14348 KB] Number of registered states: 2
[t=0.00235934s, 14348 KB] Int hash set load factor: 2/2 = 1
[t=0.00236622s, 14348 KB] Int hash set resizes: 1
[t=0.00237279s, 14348 KB] Best solution cost so far: 2
[t=0.0023793s, 14348 KB] No solution found - keep searching
[t=0.00241074s, 14348 KB] Building successor generator...done!
[t=0.0024326s, 14348 KB] peak memory difference for successor generator creation: 0 KB
[t=0.00243935s, 14348 KB] time for successor generation creation: 2.1e-07s
[t=0.00244686s, 14348 KB] Variables: 2
[t=0.00245385s, 14348 KB] FactPairs: 4
[t=0.00246051s, 14348 KB] Bytes per state: 4
[t=0.0024711s, 14348 KB] Starting search: lazy_wastar(list(hff, hlm), preferred = list(hff, hlm), w = 1)
[t=0.00247973s, 14348 KB] Conducting lazy best first search, (real) bound = 2
[t=0.0024907s, 14348 KB] 2 initial landmarks, 1 goal landmarks
[t=0.0025027s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00251046s, 14348 KB] New best heuristic value for ff: 2
[t=0.0025174s, 14348 KB] g=0, 1 evaluated, 0 expanded
[t=0.0025262s, 14348 KB] Initial heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00253322s, 14348 KB] Initial heuristic value for ff: 2
[t=0.00254304s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 1
[t=0.00255071s, 14348 KB] New best heuristic value for ff: 1
[t=0.00255754s, 14348 KB] g=1, 2 evaluated, 1 expanded
[t=0.00256564s, 14348 KB] Completely explored state space -- no solution!
[t=0.00257259s, 14348 KB] Actual search time: 8.034e-05s
[t=0.00258021s, 14348 KB] Expanded 2 state(s).
[t=0.00258694s, 14348 KB] Reopened 0 state(s).
[t=0.00259354s, 14348 KB] Evaluated 2 state(s).
[t=0.00260006s, 14348 KB] Evaluations: 4
[t=0.00260669s, 14348 KB] Generated 2 state(s).
[t=0.0026132s, 14348 KB] Dead ends: 0 state(s).
[t=0.00261965s, 14348 KB] Number of registered states: 2
[t=0.0026261s, 14348 KB] Int hash set load factor: 2/2 = 1
[t=0.0026329s, 14348 KB] Int hash set resizes: 1
[t=0.00263936s, 14348 KB] Best solution cost so far: 2
[t=0.00264611s, 14348 KB] No solution found - keep searching
[t=0.0026541s, 14348 KB] Actual search time: 0.00144964s
[t=0.00266242s, 14348 KB] Cumulative statistics:
[t=0.00266242s, 14348 KB] Expanded 10 state(s).
[t=0.00266242s, 14348 KB] Reopened 0 state(s).
[t=0.00266242s, 14348 KB] Evaluated 11 state(s).
[t=0.00266242s, 14348 KB] Evaluations: 22
[t=0.00266242s, 14348 KB] Generated 10 state(s).
[t=0.00266242s, 14348 KB] Dead ends: 0 state(s).
[t=0.00266242s, 14348 KB] Search time: 0.00145128s
[t=0.00266242s, 14348 KB] Total time: 0.00266242s
Solution found.
Peak memory: 14348 KB
Remove intermediate file output.sas
search exit code: 0

INFO     Planner time: 0.04s
/home/wbm3/anaconda3/envs/6484_dqn/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Box bound precision lowered by casting to float32[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
[32m[INFO][0m[2022-05-03 03:13:44]: [32mExploration steps: 0[0m
[32m[INFO][0m[2022-05-03 03:13:44]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000000000.pt.[0m
[32m[INFO][0m[2022-05-03 03:13:44]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:13:54]: [32mExploration steps: 5000[0m
[32m[INFO][0m[2022-05-03 03:13:54]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000005000.pt.[0m
[32m[INFO][0m[2022-05-03 03:13:54]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:14:03]: [32mExploration steps: 10000[0m
[32m[INFO][0m[2022-05-03 03:14:03]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000010000.pt.[0m
[32m[INFO][0m[2022-05-03 03:14:03]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:14:12]: [32mExploration steps: 15000[0m
[32m[INFO][0m[2022-05-03 03:14:12]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000015000.pt.[0m
[32m[INFO][0m[2022-05-03 03:14:12]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:14:23]: [32mExploration steps: 20000[0m
[32m[INFO][0m[2022-05-03 03:14:23]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000020000.pt.[0m
[32m[INFO][0m[2022-05-03 03:14:23]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:14:31]: [32mExploration steps: 25000[0m
[32m[INFO][0m[2022-05-03 03:14:31]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000025000.pt.[0m
[32m[INFO][0m[2022-05-03 03:14:31]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:14:40]: [32mExploration steps: 30000[0m
[32m[INFO][0m[2022-05-03 03:14:40]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000030000.pt.[0m
[32m[INFO][0m[2022-05-03 03:14:40]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:14:49]: [32mExploration steps: 35000[0m
[32m[INFO][0m[2022-05-03 03:14:49]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000035000.pt.[0m
[32m[INFO][0m[2022-05-03 03:14:49]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:14:58]: [32mExploration steps: 40000[0m
[32m[INFO][0m[2022-05-03 03:14:58]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000040000.pt.[0m
[32m[INFO][0m[2022-05-03 03:14:58]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:15:06]: [32mExploration steps: 45000[0m
[32m[INFO][0m[2022-05-03 03:15:06]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000045000.pt.[0m
[32m[INFO][0m[2022-05-03 03:15:16]: [32mExploration steps: 50000[0m
[32m[INFO][0m[2022-05-03 03:15:16]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000050000.pt.[0m
[32m[INFO][0m[2022-05-03 03:15:24]: [32mExploration steps: 55000[0m
[32m[INFO][0m[2022-05-03 03:15:24]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000055000.pt.[0m
[32m[INFO][0m[2022-05-03 03:15:24]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:15:33]: [32mExploration steps: 60000[0m
[32m[INFO][0m[2022-05-03 03:15:33]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000060000.pt.[0m
[32m[INFO][0m[2022-05-03 03:15:33]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:15:42]: [32mExploration steps: 65000[0m
[32m[INFO][0m[2022-05-03 03:15:42]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000065000.pt.[0m
[32m[INFO][0m[2022-05-03 03:15:42]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:15:51]: [32mExploration steps: 70000[0m
[32m[INFO][0m[2022-05-03 03:15:51]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000070000.pt.[0m
[32m[INFO][0m[2022-05-03 03:15:51]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:15:59]: [32mExploration steps: 75000[0m
[32m[INFO][0m[2022-05-03 03:15:59]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000075000.pt.[0m
[32m[INFO][0m[2022-05-03 03:15:59]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:16:08]: [32mExploration steps: 80000[0m
[32m[INFO][0m[2022-05-03 03:16:08]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000080000.pt.[0m
[32m[INFO][0m[2022-05-03 03:16:08]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:16:16]: [32mExploration steps: 85000[0m
[32m[INFO][0m[2022-05-03 03:16:16]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000085000.pt.[0m
[32m[INFO][0m[2022-05-03 03:16:16]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:16:24]: [32mExploration steps: 90000[0m
[32m[INFO][0m[2022-05-03 03:16:24]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000090000.pt.[0m
[32m[INFO][0m[2022-05-03 03:16:32]: [32mExploration steps: 95000[0m
[32m[INFO][0m[2022-05-03 03:16:32]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000095000.pt.[0m
[32m[INFO][0m[2022-05-03 03:16:41]: [32mExploration steps: 100000[0m
[32m[INFO][0m[2022-05-03 03:16:41]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000100000.pt.[0m
[32m[INFO][0m[2022-05-03 03:16:41]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:16:49]: [32mExploration steps: 105000[0m
[32m[INFO][0m[2022-05-03 03:16:49]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000105000.pt.[0m
[32m[INFO][0m[2022-05-03 03:16:49]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:16:57]: [32mExploration steps: 110000[0m
[32m[INFO][0m[2022-05-03 03:16:57]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000110000.pt.[0m
[32m[INFO][0m[2022-05-03 03:17:05]: [32mExploration steps: 115000[0m
[32m[INFO][0m[2022-05-03 03:17:05]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000115000.pt.[0m
[32m[INFO][0m[2022-05-03 03:17:13]: [32mExploration steps: 120000[0m
[32m[INFO][0m[2022-05-03 03:17:13]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000120000.pt.[0m
[32m[INFO][0m[2022-05-03 03:17:13]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:17:21]: [32mExploration steps: 125000[0m
[32m[INFO][0m[2022-05-03 03:17:21]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000125000.pt.[0m
[32m[INFO][0m[2022-05-03 03:17:29]: [32mExploration steps: 130000[0m
[32m[INFO][0m[2022-05-03 03:17:29]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000130000.pt.[0m
[32m[INFO][0m[2022-05-03 03:17:37]: [32mExploration steps: 135000[0m
[32m[INFO][0m[2022-05-03 03:17:37]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000135000.pt.[0m
[32m[INFO][0m[2022-05-03 03:17:46]: [32mExploration steps: 140000[0m
[32m[INFO][0m[2022-05-03 03:17:46]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000140000.pt.[0m
[32m[INFO][0m[2022-05-03 03:17:54]: [32mExploration steps: 145000[0m
[32m[INFO][0m[2022-05-03 03:17:54]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000145000.pt.[0m
[32m[INFO][0m[2022-05-03 03:18:02]: [32mExploration steps: 150000[0m
[32m[INFO][0m[2022-05-03 03:18:02]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000150000.pt.[0m
[32m[INFO][0m[2022-05-03 03:18:10]: [32mExploration steps: 155000[0m
[32m[INFO][0m[2022-05-03 03:18:10]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000155000.pt.[0m
[32m[INFO][0m[2022-05-03 03:18:19]: [32mExploration steps: 160000[0m
[32m[INFO][0m[2022-05-03 03:18:19]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000160000.pt.[0m
[32m[INFO][0m[2022-05-03 03:18:27]: [32mExploration steps: 165000[0m
[32m[INFO][0m[2022-05-03 03:18:27]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000165000.pt.[0m
[32m[INFO][0m[2022-05-03 03:18:35]: [32mExploration steps: 170000[0m
[32m[INFO][0m[2022-05-03 03:18:35]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000170000.pt.[0m
[32m[INFO][0m[2022-05-03 03:18:43]: [32mExploration steps: 175000[0m
[32m[INFO][0m[2022-05-03 03:18:43]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000175000.pt.[0m
[32m[INFO][0m[2022-05-03 03:18:51]: [32mExploration steps: 180000[0m
[32m[INFO][0m[2022-05-03 03:18:51]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000180000.pt.[0m
[32m[INFO][0m[2022-05-03 03:18:59]: [32mExploration steps: 185000[0m
[32m[INFO][0m[2022-05-03 03:18:59]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000185000.pt.[0m
[32m[INFO][0m[2022-05-03 03:18:59]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:19:07]: [32mExploration steps: 190000[0m
[32m[INFO][0m[2022-05-03 03:19:07]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000190000.pt.[0m
[32m[INFO][0m[2022-05-03 03:19:16]: [32mExploration steps: 195000[0m
[32m[INFO][0m[2022-05-03 03:19:16]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000195000.pt.[0m
[32m[INFO][0m[2022-05-03 03:19:24]: [32mExploration steps: 200000[0m
[32m[INFO][0m[2022-05-03 03:19:24]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/ckpt_000000200000.pt.[0m
[32m[INFO][0m[2022-05-03 03:19:24]: [32mLoading model from /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_ppo/seed_0/model/model_best.pt[0m
====================================
      Device:cuda
      Total number of steps:200000
====================================
INFO: Making new env: URReacher-v1 ({'reward_type': 'dense_handcrafted', 'gui': False, 'with_obstacle': True, 'max_episode_length': 50})
================================================
With obstacle in the scene:True
================================================
{'eval/episode_length/max': 50,
 'eval/episode_length/mean': 50.0,
 'eval/episode_length/median': 50.0,
 'eval/episode_length/min': 50,
 'eval/return/max': -20.151333,
 'eval/return/mean': -20.151333,
 'eval/return/median': -20.151333,
 'eval/return/min': -20.151333,
 'eval/smooth_return/mean': -21.470960960274684,
 'eval/success': 0.0}
ven = NVIDIA Corporation
ven = NVIDIA Corporation
Destroy EGL OpenGL window.
