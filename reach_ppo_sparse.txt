[32m[INFO][0m[2022-05-03 03:37:38]: [32mAlogrithm type:<class 'easyrl.configs.ppo_config.PPOConfig'>[0m
[32m[INFO][0m[2022-05-03 03:37:38]: [32mCreating 1 environments.[0m
pybullet build time: Mar 26 2022 03:00:15
[32m[INFO][0m[2022-05-03 03:37:38]: [32mLoad in OpenGL![0m
EGL device choice: -1 of 3.
argv[0]=
Loaded EGL 1.5 after reload.
GL_VENDOR=NVIDIA Corporation
GL_RENDERER=NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2
GL_VERSION=4.6.0 NVIDIA 470.103.01
GL_SHADING_LANGUAGE_VERSION=4.60 NVIDIA
Version = 4.6.0 NVIDIA 470.103.01
Vendor = NVIDIA Corporation
Renderer = NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2
b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
ee_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
baseb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
tool0b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
ee_tipINFO     planner time limit: None
INFO     planner memory limit: None

INFO     Running translator.
INFO     translator stdin: None
INFO     translator time limit: None
INFO     translator memory limit: None
INFO     translator command line string: /home/wbm3/anaconda3/envs/6484_dqn/bin/python /home/wbm3/Documents/GitHub/downward/builds/release/bin/translate/translate.py /home/wbm3/Documents/GitHub/airobot_reward_densification/envs/reaching_env/single_subgoal/goal-subgoal-domain.pddl /home/wbm3/Documents/GitHub/airobot_reward_densification/envs/reaching_env/single_subgoal/goal-subgoal-problem.pddl --sas-file output.sas
Parsing...
Parsing: [0.000s CPU, 0.000s wall-clock]
Normalizing task... [0.000s CPU, 0.000s wall-clock]
Instantiating...
Generating Datalog program... [0.000s CPU, 0.000s wall-clock]
Normalizing Datalog program...
Normalizing Datalog program: [0.000s CPU, 0.000s wall-clock]
Preparing model... [0.000s CPU, 0.000s wall-clock]
Generated 10 rules.
Computing model... [0.000s CPU, 0.000s wall-clock]
17 relevant atoms
8 auxiliary atoms
25 final queue length
27 total queue pushes
Completing instantiation... [0.000s CPU, 0.000s wall-clock]
Instantiating: [0.000s CPU, 0.001s wall-clock]
Computing fact groups...
Finding invariants...
3 initial candidates
Finding invariants: [0.000s CPU, 0.000s wall-clock]
Checking invariant weight... [0.000s CPU, 0.000s wall-clock]
Instantiating groups... [0.000s CPU, 0.000s wall-clock]
Collecting mutex groups... [0.000s CPU, 0.000s wall-clock]
Choosing groups...
2 uncovered facts
Choosing groups: [0.000s CPU, 0.000s wall-clock]
Building translation key... [0.000s CPU, 0.000s wall-clock]
Computing fact groups: [0.000s CPU, 0.000s wall-clock]
Building STRIPS to SAS dictionary... [0.000s CPU, 0.000s wall-clock]
Building dictionary for full mutex groups... [0.000s CPU, 0.000s wall-clock]
Building mutex information...
Building mutex information: [0.000s CPU, 0.000s wall-clock]
Translating task...
Processing axioms...
Simplifying axioms... [0.000s CPU, 0.000s wall-clock]
Translator axioms removed by simplifying: 0
Computing negative axioms... [0.000s CPU, 0.000s wall-clock]
Processing axioms: [0.000s CPU, 0.000s wall-clock]
Translating task: [0.000s CPU, 0.000s wall-clock]
1 effect conditions simplified
0 implied preconditions added
Detecting unreachable propositions...
0 operators removed
0 axioms removed
0 propositions removed
Detecting unreachable propositions: [0.000s CPU, 0.000s wall-clock]
Reordering and filtering variables...
2 of 2 variables necessary.
0 of 0 mutex groups necessary.
2 of 2 operators necessary.
0 of 0 axiom rules necessary.
Reordering and filtering variables: [0.000s CPU, 0.000s wall-clock]
Translator variables: 2
Translator derived variables: 0
Translator facts: 4
Translator goal facts: 1
Translator mutex groups: 0
Translator total mutex groups size: 0
Translator operators: 2
Translator axioms: 0
Translator task size: 15
Translator peak memory: 29696 KB
Writing output... [0.000s CPU, 0.000s wall-clock]
Done! [0.000s CPU, 0.002s wall-clock]
translate exit code: 0

INFO     Running search (release).
INFO     search stdin: output.sas
INFO     search time limit: None
INFO     search memory limit: None
INFO     search command line string: /home/wbm3/Documents/GitHub/downward/builds/release/bin/downward --if-unit-cost --evaluator 'hlm=lmcount(lm_reasonable_orders_hps(lm_rhw()),pref=true)' --evaluator 'hff=ff()' --search 'iterated([lazy_greedy([hff,hlm],preferred=[hff,hlm]),lazy_wastar([hff,hlm],preferred=[hff,hlm],w=5),lazy_wastar([hff,hlm],preferred=[hff,hlm],w=3),lazy_wastar([hff,hlm],preferred=[hff,hlm],w=2),lazy_wastar([hff,hlm],preferred=[hff,hlm],w=1)],repeat_last=true,continue_on_fail=true)' --if-non-unit-cost --evaluator 'hlm1=lmcount(lm_reasonable_orders_hps(lm_rhw()),transform=adapt_costs(one),pref=true)' --evaluator 'hff1=ff(transform=adapt_costs(one))' --evaluator 'hlm2=lmcount(lm_reasonable_orders_hps(lm_rhw()),transform=adapt_costs(plusone),pref=true)' --evaluator 'hff2=ff(transform=adapt_costs(plusone))' --search 'iterated([lazy_greedy([hff1,hlm1],preferred=[hff1,hlm1],cost_type=one,reopen_closed=false),lazy_greedy([hff2,hlm2],preferred=[hff2,hlm2],reopen_closed=false),lazy_wastar([hff2,hlm2],preferred=[hff2,hlm2],w=5),lazy_wastar([hff2,hlm2],preferred=[hff2,hlm2],w=3),lazy_wastar([hff2,hlm2],preferred=[hff2,hlm2],w=2),lazy_wastar([hff2,hlm2],preferred=[hff2,hlm2],w=1)],repeat_last=true,continue_on_fail=true)' --always --internal-plan-file sas_plan < output.sas
[t=1.846e-05s, 13696 KB] reading input...
[t=0.00012477s, 13696 KB] done reading input!
[t=0.00123396s, 14084 KB] Initializing landmark count heuristic...
[t=0.00126797s, 14084 KB] Generating landmark graph...
[t=0.00128639s, 14084 KB] Building a landmark graph with reasonable orders.
[t=0.0013001s, 14084 KB] Initializing Exploration...
[t=0.00131494s, 14084 KB] Generating landmarks using the RPG/SAS+ approach
[t=0.00135315s, 14084 KB] Removed 0 reasonable or obedient reasonable orders
[t=0.0013676s, 14084 KB] Landmarks generation time: 7.906e-05s
[t=0.00138024s, 14084 KB] Discovered 4 landmarks, of which 0 are disjunctive and 0 are conjunctive.
[t=0.00139159s, 14084 KB] 3 edges
[t=0.0014027s, 14084 KB] approx. reasonable orders
[t=0.00141582s, 14084 KB] approx. obedient reasonable orders
[t=0.00142894s, 14084 KB] Removed 0 reasonable or obedient reasonable orders
[t=0.0014402s, 14084 KB] Landmarks generation time: 0.00016574s
[t=0.00145206s, 14084 KB] Discovered 4 landmarks, of which 0 are disjunctive and 0 are conjunctive.
[t=0.00146308s, 14084 KB] 3 edges
[t=0.00147404s, 14084 KB] Landmark graph generation time: 0.00021582s
[t=0.00148543s, 14084 KB] Landmark graph contains 4 landmarks, of which 0 are disjunctive and 0 are conjunctive.
[t=0.00149606s, 14084 KB] Landmark graph contains 3 orderings.
[t=0.00153273s, 14084 KB] Simplifying 3 unary operators... done! [3 unary operators]
[t=0.00155274s, 14084 KB] time to simplify: 3.149e-05s
[t=0.00156656s, 14084 KB] Initializing additive heuristic...
[t=0.00157785s, 14084 KB] Initializing FF heuristic...
[t=0.00165299s, 14084 KB] Building successor generator...done!
[t=0.00169484s, 14084 KB] peak memory difference for successor generator creation: 0 KB
[t=0.00170618s, 14084 KB] time for successor generation creation: 3.43e-06s
[t=0.00171975s, 14084 KB] Variables: 2
[t=0.00173072s, 14084 KB] FactPairs: 4
[t=0.00174144s, 14084 KB] Bytes per state: 4
[t=0.00198835s, 14348 KB] Building successor generator...done!
[t=0.0020559s, 14348 KB] peak memory difference for successor generator creation: 0 KB
[t=0.00207208s, 14348 KB] time for successor generation creation: 3.7e-07s
[t=0.00208516s, 14348 KB] Variables: 2
[t=0.00209653s, 14348 KB] FactPairs: 4
[t=0.00210746s, 14348 KB] Bytes per state: 4
[t=0.00212913s, 14348 KB] Starting search: lazy_greedy(list(hff, hlm), preferred = list(hff, hlm))
[t=0.00214422s, 14348 KB] Conducting lazy best first search, (real) bound = 2147483647
[t=0.00216006s, 14348 KB] 2 initial landmarks, 1 goal landmarks
[t=0.00218786s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00220257s, 14348 KB] New best heuristic value for ff: 2
[t=0.00221495s, 14348 KB] g=0, 1 evaluated, 0 expanded
[t=0.00222976s, 14348 KB] Initial heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00224102s, 14348 KB] Initial heuristic value for ff: 2
[t=0.00225803s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 1
[t=0.00226987s, 14348 KB] New best heuristic value for ff: 1
[t=0.00228114s, 14348 KB] g=1, 2 evaluated, 1 expanded
[t=0.00229697s, 14348 KB] Solution found!
[t=0.00230921s, 14348 KB] Actual search time: 0.00014541s
move-to-subgoal claw subgoal (1)
move-to-goal claw subgoal goal (1)
[t=0.00235198s, 14348 KB] Plan length: 2 step(s).
[t=0.00236671s, 14348 KB] Plan cost: 2
[t=0.00237874s, 14348 KB] Expanded 2 state(s).
[t=0.00238965s, 14348 KB] Reopened 0 state(s).
[t=0.00240099s, 14348 KB] Evaluated 3 state(s).
[t=0.00241159s, 14348 KB] Evaluations: 6
[t=0.00242235s, 14348 KB] Generated 2 state(s).
[t=0.00243296s, 14348 KB] Dead ends: 0 state(s).
[t=0.00244376s, 14348 KB] Number of registered states: 3
[t=0.00245455s, 14348 KB] Int hash set load factor: 3/4 = 0.75
[t=0.00246574s, 14348 KB] Int hash set resizes: 2
[t=0.00247636s, 14348 KB] Best solution cost so far: 2
[t=0.00248689s, 14348 KB] Solution found - keep searching
[t=0.00254493s, 14348 KB] Building successor generator...done!
[t=0.00258132s, 14348 KB] peak memory difference for successor generator creation: 0 KB
[t=0.00259231s, 14348 KB] time for successor generation creation: 3.8e-07s
[t=0.00260467s, 14348 KB] Variables: 2
[t=0.00261557s, 14348 KB] FactPairs: 4
[t=0.00262639s, 14348 KB] Bytes per state: 4
[t=0.00264369s, 14348 KB] Starting search: lazy_wastar(list(hff, hlm), preferred = list(hff, hlm), w = 5)
[t=0.00265751s, 14348 KB] Conducting lazy best first search, (real) bound = 2
[t=0.00267204s, 14348 KB] 2 initial landmarks, 1 goal landmarks
[t=0.00269138s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00270356s, 14348 KB] New best heuristic value for ff: 2
[t=0.00271485s, 14348 KB] g=0, 1 evaluated, 0 expanded
[t=0.00272984s, 14348 KB] Initial heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00274112s, 14348 KB] Initial heuristic value for ff: 2
[t=0.00275783s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 1
[t=0.00277011s, 14348 KB] New best heuristic value for ff: 1
[t=0.00278119s, 14348 KB] g=1, 2 evaluated, 1 expanded
[t=0.00279463s, 14348 KB] Completely explored state space -- no solution!
[t=0.00280588s, 14348 KB] Actual search time: 0.00013202s
[t=0.00281799s, 14348 KB] Expanded 2 state(s).
[t=0.00282882s, 14348 KB] Reopened 0 state(s).
[t=0.00283972s, 14348 KB] Evaluated 2 state(s).
[t=0.00285041s, 14348 KB] Evaluations: 4
[t=0.00286098s, 14348 KB] Generated 2 state(s).
[t=0.00287159s, 14348 KB] Dead ends: 0 state(s).
[t=0.00288215s, 14348 KB] Number of registered states: 2
[t=0.00289287s, 14348 KB] Int hash set load factor: 2/2 = 1
[t=0.00290435s, 14348 KB] Int hash set resizes: 1
[t=0.00291497s, 14348 KB] Best solution cost so far: 2
[t=0.0029257s, 14348 KB] No solution found - keep searching
[t=0.00297679s, 14348 KB] Building successor generator...done!
[t=0.00301287s, 14348 KB] peak memory difference for successor generator creation: 0 KB
[t=0.00302361s, 14348 KB] time for successor generation creation: 3.6e-07s
[t=0.0030361s, 14348 KB] Variables: 2
[t=0.00305163s, 14348 KB] FactPairs: 4
[t=0.00306338s, 14348 KB] Bytes per state: 4
[t=0.00308076s, 14348 KB] Starting search: lazy_wastar(list(hff, hlm), preferred = list(hff, hlm), w = 3)
[t=0.00309429s, 14348 KB] Conducting lazy best first search, (real) bound = 2
[t=0.00310785s, 14348 KB] 2 initial landmarks, 1 goal landmarks
[t=0.00312627s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00313875s, 14348 KB] New best heuristic value for ff: 2
[t=0.00314993s, 14348 KB] g=0, 1 evaluated, 0 expanded
[t=0.00316381s, 14348 KB] Initial heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00317506s, 14348 KB] Initial heuristic value for ff: 2
[t=0.00319122s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 1
[t=0.00320348s, 14348 KB] New best heuristic value for ff: 1
[t=0.00321465s, 14348 KB] g=1, 2 evaluated, 1 expanded
[t=0.00322842s, 14348 KB] Completely explored state space -- no solution!
[t=0.00323953s, 14348 KB] Actual search time: 0.00012987s
[t=0.00325154s, 14348 KB] Expanded 2 state(s).
[t=0.00326223s, 14348 KB] Reopened 0 state(s).
[t=0.00327306s, 14348 KB] Evaluated 2 state(s).
[t=0.00328385s, 14348 KB] Evaluations: 4
[t=0.00329466s, 14348 KB] Generated 2 state(s).
[t=0.0033052s, 14348 KB] Dead ends: 0 state(s).
[t=0.00331616s, 14348 KB] Number of registered states: 2
[t=0.00332722s, 14348 KB] Int hash set load factor: 2/2 = 1
[t=0.0033388s, 14348 KB] Int hash set resizes: 1
[t=0.00334946s, 14348 KB] Best solution cost so far: 2
[t=0.00335996s, 14348 KB] No solution found - keep searching
[t=0.00340946s, 14348 KB] Building successor generator...done!
[t=0.00344524s, 14348 KB] peak memory difference for successor generator creation: 0 KB
[t=0.00345616s, 14348 KB] time for successor generation creation: 3.3e-07s
[t=0.00346872s, 14348 KB] Variables: 2
[t=0.00347968s, 14348 KB] FactPairs: 4
[t=0.00349042s, 14348 KB] Bytes per state: 4
[t=0.00350749s, 14348 KB] Starting search: lazy_wastar(list(hff, hlm), preferred = list(hff, hlm), w = 2)
[t=0.00352128s, 14348 KB] Conducting lazy best first search, (real) bound = 2
[t=0.00353479s, 14348 KB] 2 initial landmarks, 1 goal landmarks
[t=0.00355294s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00356507s, 14348 KB] New best heuristic value for ff: 2
[t=0.0035761s, 14348 KB] g=0, 1 evaluated, 0 expanded
[t=0.00358999s, 14348 KB] Initial heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.0036013s, 14348 KB] Initial heuristic value for ff: 2
[t=0.00361731s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 1
[t=0.00362937s, 14348 KB] New best heuristic value for ff: 1
[t=0.0036404s, 14348 KB] g=1, 2 evaluated, 1 expanded
[t=0.00365344s, 14348 KB] Completely explored state space -- no solution!
[t=0.00366469s, 14348 KB] Actual search time: 0.000128061s
[t=0.00367663s, 14348 KB] Expanded 2 state(s).
[t=0.00368728s, 14348 KB] Reopened 0 state(s).
[t=0.00369792s, 14348 KB] Evaluated 2 state(s).
[t=0.0037087s, 14348 KB] Evaluations: 4
[t=0.00371952s, 14348 KB] Generated 2 state(s).
[t=0.00373027s, 14348 KB] Dead ends: 0 state(s).
[t=0.00374086s, 14348 KB] Number of registered states: 2
[t=0.00375144s, 14348 KB] Int hash set load factor: 2/2 = 1
[t=0.00376264s, 14348 KB] Int hash set resizes: 1
[t=0.00377319s, 14348 KB] Best solution cost so far: 2
[t=0.00378373s, 14348 KB] No solution found - keep searching
[t=0.00383246s, 14348 KB] Building successor generator...done!
[t=0.00386753s, 14348 KB] peak memory difference for successor generator creation: 0 KB
[t=0.00387832s, 14348 KB] time for successor generation creation: 3.4e-07s
[t=0.00389066s, 14348 KB] Variables: 2
[t=0.00390164s, 14348 KB] FactPairs: 4
[t=0.00391243s, 14348 KB] Bytes per state: 4
[t=0.00392909s, 14348 KB] Starting search: lazy_wastar(list(hff, hlm), preferred = list(hff, hlm), w = 1)
[t=0.00394266s, 14348 KB] Conducting lazy best first search, (real) bound = 2
[t=0.00395983s, 14348 KB] 2 initial landmarks, 1 goal landmarks
[t=0.00397926s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00399164s, 14348 KB] New best heuristic value for ff: 2
[t=0.00400302s, 14348 KB] g=0, 1 evaluated, 0 expanded
[t=0.00401699s, 14348 KB] Initial heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00402852s, 14348 KB] Initial heuristic value for ff: 2
[t=0.00405556s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 1
[t=0.00406967s, 14348 KB] New best heuristic value for ff: 1
[t=0.00408095s, 14348 KB] g=1, 2 evaluated, 1 expanded
[t=0.00409435s, 14348 KB] Completely explored state space -- no solution!
[t=0.00410571s, 14348 KB] Actual search time: 0.00014321s
[t=0.00411828s, 14348 KB] Expanded 2 state(s).
[t=0.00412899s, 14348 KB] Reopened 0 state(s).
[t=0.00413984s, 14348 KB] Evaluated 2 state(s).
[t=0.00415059s, 14348 KB] Evaluations: 4
[t=0.00416124s, 14348 KB] Generated 2 state(s).
[t=0.00417188s, 14348 KB] Dead ends: 0 state(s).
[t=0.00418255s, 14348 KB] Number of registered states: 2
[t=0.00419322s, 14348 KB] Int hash set load factor: 2/2 = 1
[t=0.00420489s, 14348 KB] Int hash set resizes: 1
[t=0.00421582s, 14348 KB] Best solution cost so far: 2
[t=0.00422695s, 14348 KB] No solution found - keep searching
[t=0.00424056s, 14348 KB] Actual search time: 0.00229968s
[t=0.00425352s, 14348 KB] Cumulative statistics:
[t=0.00425352s, 14348 KB] Expanded 10 state(s).
[t=0.00425352s, 14348 KB] Reopened 0 state(s).
[t=0.00425352s, 14348 KB] Evaluated 11 state(s).
[t=0.00425352s, 14348 KB] Evaluations: 22
[t=0.00425352s, 14348 KB] Generated 10 state(s).
[t=0.00425352s, 14348 KB] Dead ends: 0 state(s).
[t=0.00425352s, 14348 KB] Search time: 0.00230224s
[t=0.00425352s, 14348 KB] Total time: 0.00425352s
Solution found.
Peak memory: 14348 KB
Remove intermediate file output.sas
search exit code: 0

INFO     Planner time: 0.05s
/home/wbm3/anaconda3/envs/6484_dqn/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Box bound precision lowered by casting to float32[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
[32m[INFO][0m[2022-05-03 03:37:41]: [32mExploration steps: 0[0m
[32m[INFO][0m[2022-05-03 03:37:41]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000000000.pt.[0m
[32m[INFO][0m[2022-05-03 03:37:41]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:37:50]: [32mExploration steps: 5000[0m
[32m[INFO][0m[2022-05-03 03:37:50]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000005000.pt.[0m
[32m[INFO][0m[2022-05-03 03:37:58]: [32mExploration steps: 10000[0m
[32m[INFO][0m[2022-05-03 03:37:58]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000010000.pt.[0m
[32m[INFO][0m[2022-05-03 03:38:06]: [32mExploration steps: 15000[0m
[32m[INFO][0m[2022-05-03 03:38:06]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000015000.pt.[0m
[32m[INFO][0m[2022-05-03 03:38:14]: [32mExploration steps: 20000[0m
[32m[INFO][0m[2022-05-03 03:38:14]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000020000.pt.[0m
[32m[INFO][0m[2022-05-03 03:38:22]: [32mExploration steps: 25000[0m
[32m[INFO][0m[2022-05-03 03:38:22]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000025000.pt.[0m
[32m[INFO][0m[2022-05-03 03:38:30]: [32mExploration steps: 30000[0m
[32m[INFO][0m[2022-05-03 03:38:30]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000030000.pt.[0m
[32m[INFO][0m[2022-05-03 03:38:38]: [32mExploration steps: 35000[0m
[32m[INFO][0m[2022-05-03 03:38:38]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000035000.pt.[0m
[32m[INFO][0m[2022-05-03 03:38:46]: [32mExploration steps: 40000[0m
[32m[INFO][0m[2022-05-03 03:38:46]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000040000.pt.[0m
[32m[INFO][0m[2022-05-03 03:38:55]: [32mExploration steps: 45000[0m
[32m[INFO][0m[2022-05-03 03:38:55]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000045000.pt.[0m
[32m[INFO][0m[2022-05-03 03:39:03]: [32mExploration steps: 50000[0m
[32m[INFO][0m[2022-05-03 03:39:03]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000050000.pt.[0m
[32m[INFO][0m[2022-05-03 03:39:12]: [32mExploration steps: 55000[0m
[32m[INFO][0m[2022-05-03 03:39:12]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000055000.pt.[0m
[32m[INFO][0m[2022-05-03 03:39:22]: [32mExploration steps: 60000[0m
[32m[INFO][0m[2022-05-03 03:39:22]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000060000.pt.[0m
[32m[INFO][0m[2022-05-03 03:39:31]: [32mExploration steps: 65000[0m
[32m[INFO][0m[2022-05-03 03:39:31]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000065000.pt.[0m
[32m[INFO][0m[2022-05-03 03:39:41]: [32mExploration steps: 70000[0m
[32m[INFO][0m[2022-05-03 03:39:41]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000070000.pt.[0m
[32m[INFO][0m[2022-05-03 03:39:51]: [32mExploration steps: 75000[0m
[32m[INFO][0m[2022-05-03 03:39:51]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000075000.pt.[0m
[32m[INFO][0m[2022-05-03 03:40:01]: [32mExploration steps: 80000[0m
[32m[INFO][0m[2022-05-03 03:40:01]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000080000.pt.[0m
[32m[INFO][0m[2022-05-03 03:40:10]: [32mExploration steps: 85000[0m
[32m[INFO][0m[2022-05-03 03:40:10]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000085000.pt.[0m
[32m[INFO][0m[2022-05-03 03:40:18]: [32mExploration steps: 90000[0m
[32m[INFO][0m[2022-05-03 03:40:18]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000090000.pt.[0m
[32m[INFO][0m[2022-05-03 03:40:28]: [32mExploration steps: 95000[0m
[32m[INFO][0m[2022-05-03 03:40:28]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000095000.pt.[0m
[32m[INFO][0m[2022-05-03 03:40:38]: [32mExploration steps: 100000[0m
[32m[INFO][0m[2022-05-03 03:40:38]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000100000.pt.[0m
[32m[INFO][0m[2022-05-03 03:40:48]: [32mExploration steps: 105000[0m
[32m[INFO][0m[2022-05-03 03:40:48]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000105000.pt.[0m
[32m[INFO][0m[2022-05-03 03:40:57]: [32mExploration steps: 110000[0m
[32m[INFO][0m[2022-05-03 03:40:57]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000110000.pt.[0m
[32m[INFO][0m[2022-05-03 03:41:07]: [32mExploration steps: 115000[0m
[32m[INFO][0m[2022-05-03 03:41:07]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000115000.pt.[0m
[32m[INFO][0m[2022-05-03 03:41:16]: [32mExploration steps: 120000[0m
[32m[INFO][0m[2022-05-03 03:41:16]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000120000.pt.[0m
[32m[INFO][0m[2022-05-03 03:41:25]: [32mExploration steps: 125000[0m
[32m[INFO][0m[2022-05-03 03:41:25]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000125000.pt.[0m
[32m[INFO][0m[2022-05-03 03:41:35]: [32mExploration steps: 130000[0m
[32m[INFO][0m[2022-05-03 03:41:35]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000130000.pt.[0m
[32m[INFO][0m[2022-05-03 03:41:45]: [32mExploration steps: 135000[0m
[32m[INFO][0m[2022-05-03 03:41:45]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000135000.pt.[0m
[32m[INFO][0m[2022-05-03 03:41:54]: [32mExploration steps: 140000[0m
[32m[INFO][0m[2022-05-03 03:41:54]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000140000.pt.[0m
[32m[INFO][0m[2022-05-03 03:42:04]: [32mExploration steps: 145000[0m
[32m[INFO][0m[2022-05-03 03:42:04]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000145000.pt.[0m
[32m[INFO][0m[2022-05-03 03:42:13]: [32mExploration steps: 150000[0m
[32m[INFO][0m[2022-05-03 03:42:13]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000150000.pt.[0m
[32m[INFO][0m[2022-05-03 03:42:22]: [32mExploration steps: 155000[0m
[32m[INFO][0m[2022-05-03 03:42:22]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000155000.pt.[0m
[32m[INFO][0m[2022-05-03 03:42:31]: [32mExploration steps: 160000[0m
[32m[INFO][0m[2022-05-03 03:42:31]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000160000.pt.[0m
[32m[INFO][0m[2022-05-03 03:42:41]: [32mExploration steps: 165000[0m
[32m[INFO][0m[2022-05-03 03:42:41]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000165000.pt.[0m
[32m[INFO][0m[2022-05-03 03:42:51]: [32mExploration steps: 170000[0m
[32m[INFO][0m[2022-05-03 03:42:51]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000170000.pt.[0m
[32m[INFO][0m[2022-05-03 03:43:01]: [32mExploration steps: 175000[0m
[32m[INFO][0m[2022-05-03 03:43:01]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000175000.pt.[0m
[32m[INFO][0m[2022-05-03 03:43:11]: [32mExploration steps: 180000[0m
[32m[INFO][0m[2022-05-03 03:43:11]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000180000.pt.[0m
[32m[INFO][0m[2022-05-03 03:43:21]: [32mExploration steps: 185000[0m
[32m[INFO][0m[2022-05-03 03:43:21]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000185000.pt.[0m
[32m[INFO][0m[2022-05-03 03:43:31]: [32mExploration steps: 190000[0m
[32m[INFO][0m[2022-05-03 03:43:31]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000190000.pt.[0m
[32m[INFO][0m[2022-05-03 03:43:41]: [32mExploration steps: 195000[0m
[32m[INFO][0m[2022-05-03 03:43:41]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000195000.pt.[0m
[32m[INFO][0m[2022-05-03 03:43:51]: [32mExploration steps: 200000[0m
[32m[INFO][0m[2022-05-03 03:43:51]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/ckpt_000000200000.pt.[0m
[32m[INFO][0m[2022-05-03 03:43:51]: [32mLoading model from /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_sparse_handcrafted_ppo/seed_0/model/model_best.pt[0m
====================================
      Device:cuda
      Total number of steps:200000
====================================
INFO: Making new env: URReacher-v1 ({'reward_type': 'sparse_handcrafted', 'gui': False, 'with_obstacle': True, 'max_episode_length': 50})
================================================
With obstacle in the scene:True
================================================
{'eval/episode_length/max': 50,
 'eval/episode_length/mean': 50.0,
 'eval/episode_length/median': 50.0,
 'eval/episode_length/min': 50,
 'eval/return/max': 0.0,
 'eval/return/mean': 0.0,
 'eval/return/median': 0.0,
 'eval/return/min': 0.0,
 'eval/smooth_return/mean': 0.0,
 'eval/success': 0.0}
ven = NVIDIA Corporation
ven = NVIDIA Corporation
Destroy EGL OpenGL window.
