[32m[INFO][0m[2022-05-03 02:54:57]: [32mAlogrithm type:<class 'easyrl.configs.sac_config.SACConfig'>[0m
[32m[INFO][0m[2022-05-03 02:54:57]: [32mCreating 1 environments.[0m
pybullet build time: Mar 26 2022 03:00:15
[32m[INFO][0m[2022-05-03 02:54:57]: [32mLoad in OpenGL![0m
EGL device choice: -1 of 3.
argv[0]=
Loaded EGL 1.5 after reload.
GL_VENDOR=NVIDIA Corporation
GL_RENDERER=NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2
GL_VERSION=4.6.0 NVIDIA 470.103.01
GL_SHADING_LANGUAGE_VERSION=4.60 NVIDIA
Version = 4.6.0 NVIDIA 470.103.01
Vendor = NVIDIA Corporation
Renderer = NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2
b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
ee_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
baseb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
tool0b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
ee_tipINFO     planner time limit: None
INFO     planner memory limit: None

INFO     Running translator.
INFO     translator stdin: None
INFO     translator time limit: None
INFO     translator memory limit: None
INFO     translator command line string: /home/wbm3/anaconda3/envs/6484_dqn/bin/python /home/wbm3/Documents/GitHub/downward/builds/release/bin/translate/translate.py /home/wbm3/Documents/GitHub/airobot_reward_densification/envs/reaching_env/single_subgoal/goal-subgoal-domain.pddl /home/wbm3/Documents/GitHub/airobot_reward_densification/envs/reaching_env/single_subgoal/goal-subgoal-problem.pddl --sas-file output.sas
Parsing...
Parsing: [0.000s CPU, 0.000s wall-clock]
Normalizing task... [0.000s CPU, 0.000s wall-clock]
Instantiating...
Generating Datalog program... [0.000s CPU, 0.000s wall-clock]
Normalizing Datalog program...
Normalizing Datalog program: [0.000s CPU, 0.000s wall-clock]
Preparing model... [0.000s CPU, 0.000s wall-clock]
Generated 10 rules.
Computing model... [0.000s CPU, 0.000s wall-clock]
17 relevant atoms
8 auxiliary atoms
25 final queue length
27 total queue pushes
Completing instantiation... [0.000s CPU, 0.000s wall-clock]
Instantiating: [0.000s CPU, 0.001s wall-clock]
Computing fact groups...
Finding invariants...
3 initial candidates
Finding invariants: [0.000s CPU, 0.000s wall-clock]
Checking invariant weight... [0.000s CPU, 0.000s wall-clock]
Instantiating groups... [0.000s CPU, 0.000s wall-clock]
Collecting mutex groups... [0.000s CPU, 0.000s wall-clock]
Choosing groups...
2 uncovered facts
Choosing groups: [0.000s CPU, 0.000s wall-clock]
Building translation key... [0.000s CPU, 0.000s wall-clock]
Computing fact groups: [0.000s CPU, 0.000s wall-clock]
Building STRIPS to SAS dictionary... [0.000s CPU, 0.000s wall-clock]
Building dictionary for full mutex groups... [0.000s CPU, 0.000s wall-clock]
Building mutex information...
Building mutex information: [0.000s CPU, 0.000s wall-clock]
Translating task...
Processing axioms...
Simplifying axioms... [0.000s CPU, 0.000s wall-clock]
Translator axioms removed by simplifying: 0
Computing negative axioms... [0.000s CPU, 0.000s wall-clock]
Processing axioms: [0.000s CPU, 0.000s wall-clock]
Translating task: [0.000s CPU, 0.000s wall-clock]
1 effect conditions simplified
0 implied preconditions added
Detecting unreachable propositions...
0 operators removed
0 axioms removed
0 propositions removed
Detecting unreachable propositions: [0.000s CPU, 0.000s wall-clock]
Reordering and filtering variables...
2 of 2 variables necessary.
0 of 0 mutex groups necessary.
2 of 2 operators necessary.
0 of 0 axiom rules necessary.
Reordering and filtering variables: [0.000s CPU, 0.000s wall-clock]
Translator variables: 2
Translator derived variables: 0
Translator facts: 4
Translator goal facts: 1
Translator mutex groups: 0
Translator total mutex groups size: 0
Translator operators: 2
Translator axioms: 0
Translator task size: 15
Translator peak memory: 29696 KB
Writing output... [0.000s CPU, 0.000s wall-clock]
Done! [0.000s CPU, 0.002s wall-clock]
translate exit code: 0

INFO     Running search (release).
INFO     search stdin: output.sas
INFO     search time limit: None
INFO     search memory limit: None
INFO     search command line string: /home/wbm3/Documents/GitHub/downward/builds/release/bin/downward --if-unit-cost --evaluator 'hlm=lmcount(lm_reasonable_orders_hps(lm_rhw()),pref=true)' --evaluator 'hff=ff()' --search 'iterated([lazy_greedy([hff,hlm],preferred=[hff,hlm]),lazy_wastar([hff,hlm],preferred=[hff,hlm],w=5),lazy_wastar([hff,hlm],preferred=[hff,hlm],w=3),lazy_wastar([hff,hlm],preferred=[hff,hlm],w=2),lazy_wastar([hff,hlm],preferred=[hff,hlm],w=1)],repeat_last=true,continue_on_fail=true)' --if-non-unit-cost --evaluator 'hlm1=lmcount(lm_reasonable_orders_hps(lm_rhw()),transform=adapt_costs(one),pref=true)' --evaluator 'hff1=ff(transform=adapt_costs(one))' --evaluator 'hlm2=lmcount(lm_reasonable_orders_hps(lm_rhw()),transform=adapt_costs(plusone),pref=true)' --evaluator 'hff2=ff(transform=adapt_costs(plusone))' --search 'iterated([lazy_greedy([hff1,hlm1],preferred=[hff1,hlm1],cost_type=one,reopen_closed=false),lazy_greedy([hff2,hlm2],preferred=[hff2,hlm2],reopen_closed=false),lazy_wastar([hff2,hlm2],preferred=[hff2,hlm2],w=5),lazy_wastar([hff2,hlm2],preferred=[hff2,hlm2],w=3),lazy_wastar([hff2,hlm2],preferred=[hff2,hlm2],w=2),lazy_wastar([hff2,hlm2],preferred=[hff2,hlm2],w=1)],repeat_last=true,continue_on_fail=true)' --always --internal-plan-file sas_plan < output.sas
[t=1.817e-05s, 13696 KB] reading input...
[t=0.00011116s, 13696 KB] done reading input!
[t=0.00121951s, 14084 KB] Initializing landmark count heuristic...
[t=0.00125376s, 14084 KB] Generating landmark graph...
[t=0.00127217s, 14084 KB] Building a landmark graph with reasonable orders.
[t=0.00128673s, 14084 KB] Initializing Exploration...
[t=0.00130218s, 14084 KB] Generating landmarks using the RPG/SAS+ approach
[t=0.00134099s, 14084 KB] Removed 0 reasonable or obedient reasonable orders
[t=0.00135508s, 14084 KB] Landmarks generation time: 8.023e-05s
[t=0.00137264s, 14084 KB] Discovered 4 landmarks, of which 0 are disjunctive and 0 are conjunctive.
[t=0.00138481s, 14084 KB] 3 edges
[t=0.00139671s, 14084 KB] approx. reasonable orders
[t=0.00141046s, 14084 KB] approx. obedient reasonable orders
[t=0.00142275s, 14084 KB] Removed 0 reasonable or obedient reasonable orders
[t=0.00143672s, 14084 KB] Landmarks generation time: 0.0001768s
[t=0.00144882s, 14084 KB] Discovered 4 landmarks, of which 0 are disjunctive and 0 are conjunctive.
[t=0.00145968s, 14084 KB] 3 edges
[t=0.00147046s, 14084 KB] Landmark graph generation time: 0.00022664s
[t=0.00148196s, 14084 KB] Landmark graph contains 4 landmarks, of which 0 are disjunctive and 0 are conjunctive.
[t=0.00149254s, 14084 KB] Landmark graph contains 3 orderings.
[t=0.00152999s, 14084 KB] Simplifying 3 unary operators... done! [3 unary operators]
[t=0.00154965s, 14084 KB] time to simplify: 3.063e-05s
[t=0.0015629s, 14084 KB] Initializing additive heuristic...
[t=0.00157387s, 14084 KB] Initializing FF heuristic...
[t=0.00164884s, 14084 KB] Building successor generator...done!
[t=0.00169067s, 14084 KB] peak memory difference for successor generator creation: 0 KB
[t=0.00170167s, 14084 KB] time for successor generation creation: 3.2e-06s
[t=0.00171468s, 14084 KB] Variables: 2
[t=0.00172585s, 14084 KB] FactPairs: 4
[t=0.0017369s, 14084 KB] Bytes per state: 4
[t=0.00198297s, 14348 KB] Building successor generator...done!
[t=0.00205136s, 14348 KB] peak memory difference for successor generator creation: 0 KB
[t=0.00206729s, 14348 KB] time for successor generation creation: 3.9e-07s
[t=0.00208081s, 14348 KB] Variables: 2
[t=0.0020923s, 14348 KB] FactPairs: 4
[t=0.00210316s, 14348 KB] Bytes per state: 4
[t=0.00212585s, 14348 KB] Starting search: lazy_greedy(list(hff, hlm), preferred = list(hff, hlm))
[t=0.0021416s, 14348 KB] Conducting lazy best first search, (real) bound = 2147483647
[t=0.00215793s, 14348 KB] 2 initial landmarks, 1 goal landmarks
[t=0.00218549s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00219977s, 14348 KB] New best heuristic value for ff: 2
[t=0.00221137s, 14348 KB] g=0, 1 evaluated, 0 expanded
[t=0.00222543s, 14348 KB] Initial heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00223739s, 14348 KB] Initial heuristic value for ff: 2
[t=0.00225485s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 1
[t=0.00226675s, 14348 KB] New best heuristic value for ff: 1
[t=0.00227761s, 14348 KB] g=1, 2 evaluated, 1 expanded
[t=0.00229285s, 14348 KB] Solution found!
[t=0.00230523s, 14348 KB] Actual search time: 0.00014327s
move-to-subgoal claw subgoal (1)
move-to-goal claw subgoal goal (1)
[t=0.00234728s, 14348 KB] Plan length: 2 step(s).
[t=0.00236262s, 14348 KB] Plan cost: 2
[t=0.0023746s, 14348 KB] Expanded 2 state(s).
[t=0.00238541s, 14348 KB] Reopened 0 state(s).
[t=0.00239627s, 14348 KB] Evaluated 3 state(s).
[t=0.00240728s, 14348 KB] Evaluations: 6
[t=0.0024181s, 14348 KB] Generated 2 state(s).
[t=0.0024287s, 14348 KB] Dead ends: 0 state(s).
[t=0.00243963s, 14348 KB] Number of registered states: 3
[t=0.00245032s, 14348 KB] Int hash set load factor: 3/4 = 0.75
[t=0.00246179s, 14348 KB] Int hash set resizes: 2
[t=0.00247247s, 14348 KB] Best solution cost so far: 2
[t=0.00248329s, 14348 KB] Solution found - keep searching
[t=0.0025411s, 14348 KB] Building successor generator...done!
[t=0.00257726s, 14348 KB] peak memory difference for successor generator creation: 0 KB
[t=0.0025883s, 14348 KB] time for successor generation creation: 4e-07s
[t=0.00260074s, 14348 KB] Variables: 2
[t=0.00261171s, 14348 KB] FactPairs: 4
[t=0.00262236s, 14348 KB] Bytes per state: 4
[t=0.00263917s, 14348 KB] Starting search: lazy_wastar(list(hff, hlm), preferred = list(hff, hlm), w = 5)
[t=0.0026529s, 14348 KB] Conducting lazy best first search, (real) bound = 2
[t=0.00266736s, 14348 KB] 2 initial landmarks, 1 goal landmarks
[t=0.00268637s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00269855s, 14348 KB] New best heuristic value for ff: 2
[t=0.00270981s, 14348 KB] g=0, 1 evaluated, 0 expanded
[t=0.00272386s, 14348 KB] Initial heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00273553s, 14348 KB] Initial heuristic value for ff: 2
[t=0.00275202s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 1
[t=0.00276487s, 14348 KB] New best heuristic value for ff: 1
[t=0.0027759s, 14348 KB] g=1, 2 evaluated, 1 expanded
[t=0.00278921s, 14348 KB] Completely explored state space -- no solution!
[t=0.00280049s, 14348 KB] Actual search time: 0.00013136s
[t=0.00281229s, 14348 KB] Expanded 2 state(s).
[t=0.00282307s, 14348 KB] Reopened 0 state(s).
[t=0.00283414s, 14348 KB] Evaluated 2 state(s).
[t=0.00284486s, 14348 KB] Evaluations: 4
[t=0.00285551s, 14348 KB] Generated 2 state(s).
[t=0.00286615s, 14348 KB] Dead ends: 0 state(s).
[t=0.00287743s, 14348 KB] Number of registered states: 2
[t=0.00288824s, 14348 KB] Int hash set load factor: 2/2 = 1
[t=0.00289979s, 14348 KB] Int hash set resizes: 1
[t=0.00291086s, 14348 KB] Best solution cost so far: 2
[t=0.0029216s, 14348 KB] No solution found - keep searching
[t=0.00297297s, 14348 KB] Building successor generator...done!
[t=0.0030084s, 14348 KB] peak memory difference for successor generator creation: 0 KB
[t=0.00301931s, 14348 KB] time for successor generation creation: 3.7e-07s
[t=0.00303164s, 14348 KB] Variables: 2
[t=0.00304288s, 14348 KB] FactPairs: 4
[t=0.00305777s, 14348 KB] Bytes per state: 4
[t=0.00307581s, 14348 KB] Starting search: lazy_wastar(list(hff, hlm), preferred = list(hff, hlm), w = 3)
[t=0.00308961s, 14348 KB] Conducting lazy best first search, (real) bound = 2
[t=0.00310314s, 14348 KB] 2 initial landmarks, 1 goal landmarks
[t=0.00312116s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00313329s, 14348 KB] New best heuristic value for ff: 2
[t=0.00314467s, 14348 KB] g=0, 1 evaluated, 0 expanded
[t=0.00315879s, 14348 KB] Initial heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00317013s, 14348 KB] Initial heuristic value for ff: 2
[t=0.00318665s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 1
[t=0.00319874s, 14348 KB] New best heuristic value for ff: 1
[t=0.00321002s, 14348 KB] g=1, 2 evaluated, 1 expanded
[t=0.00322334s, 14348 KB] Completely explored state space -- no solution!
[t=0.00323461s, 14348 KB] Actual search time: 0.00012963s
[t=0.00324648s, 14348 KB] Expanded 2 state(s).
[t=0.00325758s, 14348 KB] Reopened 0 state(s).
[t=0.0032683s, 14348 KB] Evaluated 2 state(s).
[t=0.00327917s, 14348 KB] Evaluations: 4
[t=0.00329033s, 14348 KB] Generated 2 state(s).
[t=0.00330096s, 14348 KB] Dead ends: 0 state(s).
[t=0.00331172s, 14348 KB] Number of registered states: 2
[t=0.00332255s, 14348 KB] Int hash set load factor: 2/2 = 1
[t=0.00333416s, 14348 KB] Int hash set resizes: 1
[t=0.00334509s, 14348 KB] Best solution cost so far: 2
[t=0.00335589s, 14348 KB] No solution found - keep searching
[t=0.00340569s, 14348 KB] Building successor generator...done!
[t=0.00344065s, 14348 KB] peak memory difference for successor generator creation: 0 KB
[t=0.00345139s, 14348 KB] time for successor generation creation: 3.6e-07s
[t=0.00346377s, 14348 KB] Variables: 2
[t=0.00347466s, 14348 KB] FactPairs: 4
[t=0.00348544s, 14348 KB] Bytes per state: 4
[t=0.00350176s, 14348 KB] Starting search: lazy_wastar(list(hff, hlm), preferred = list(hff, hlm), w = 2)
[t=0.00351529s, 14348 KB] Conducting lazy best first search, (real) bound = 2
[t=0.00352904s, 14348 KB] 2 initial landmarks, 1 goal landmarks
[t=0.0035468s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.003559s, 14348 KB] New best heuristic value for ff: 2
[t=0.00357037s, 14348 KB] g=0, 1 evaluated, 0 expanded
[t=0.00358417s, 14348 KB] Initial heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00359564s, 14348 KB] Initial heuristic value for ff: 2
[t=0.00361184s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 1
[t=0.00362398s, 14348 KB] New best heuristic value for ff: 1
[t=0.00363526s, 14348 KB] g=1, 2 evaluated, 1 expanded
[t=0.00365935s, 14348 KB] Completely explored state space -- no solution!
[t=0.0036722s, 14348 KB] Actual search time: 0.00014195s
[t=0.00368709s, 14348 KB] Expanded 2 state(s).
[t=0.00369828s, 14348 KB] Reopened 0 state(s).
[t=0.00370903s, 14348 KB] Evaluated 2 state(s).
[t=0.0037201s, 14348 KB] Evaluations: 4
[t=0.00373117s, 14348 KB] Generated 2 state(s).
[t=0.0037419s, 14348 KB] Dead ends: 0 state(s).
[t=0.00375269s, 14348 KB] Number of registered states: 2
[t=0.00376391s, 14348 KB] Int hash set load factor: 2/2 = 1
[t=0.00377539s, 14348 KB] Int hash set resizes: 1
[t=0.00378611s, 14348 KB] Best solution cost so far: 2
[t=0.00379689s, 14348 KB] No solution found - keep searching
[t=0.00384632s, 14348 KB] Building successor generator...done!
[t=0.00388137s, 14348 KB] peak memory difference for successor generator creation: 0 KB
[t=0.0038921s, 14348 KB] time for successor generation creation: 3.9e-07s
[t=0.00390427s, 14348 KB] Variables: 2
[t=0.00391529s, 14348 KB] FactPairs: 4
[t=0.00392614s, 14348 KB] Bytes per state: 4
[t=0.00394297s, 14348 KB] Starting search: lazy_wastar(list(hff, hlm), preferred = list(hff, hlm), w = 1)
[t=0.00395648s, 14348 KB] Conducting lazy best first search, (real) bound = 2
[t=0.00397459s, 14348 KB] 2 initial landmarks, 1 goal landmarks
[t=0.00399405s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00400652s, 14348 KB] New best heuristic value for ff: 2
[t=0.00401769s, 14348 KB] g=0, 1 evaluated, 0 expanded
[t=0.0040314s, 14348 KB] Initial heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 2
[t=0.00404298s, 14348 KB] Initial heuristic value for ff: 2
[t=0.00405896s, 14348 KB] New best heuristic value for lmcount(lm_reasonable_orders_hps(lm_rhw), pref = true): 1
[t=0.00407104s, 14348 KB] New best heuristic value for ff: 1
[t=0.00408248s, 14348 KB] g=1, 2 evaluated, 1 expanded
[t=0.00409566s, 14348 KB] Completely explored state space -- no solution!
[t=0.00410744s, 14348 KB] Actual search time: 0.00012973s
[t=0.0041192s, 14348 KB] Expanded 2 state(s).
[t=0.00412991s, 14348 KB] Reopened 0 state(s).
[t=0.00414091s, 14348 KB] Evaluated 2 state(s).
[t=0.00415186s, 14348 KB] Evaluations: 4
[t=0.00416307s, 14348 KB] Generated 2 state(s).
[t=0.00417374s, 14348 KB] Dead ends: 0 state(s).
[t=0.00418496s, 14348 KB] Number of registered states: 2
[t=0.00419608s, 14348 KB] Int hash set load factor: 2/2 = 1
[t=0.00420739s, 14348 KB] Int hash set resizes: 1
[t=0.00421807s, 14348 KB] Best solution cost so far: 2
[t=0.00422879s, 14348 KB] No solution found - keep searching
[t=0.00424206s, 14348 KB] Actual search time: 0.00230692s
[t=0.00425526s, 14348 KB] Cumulative statistics:
[t=0.00425526s, 14348 KB] Expanded 10 state(s).
[t=0.00425526s, 14348 KB] Reopened 0 state(s).
[t=0.00425526s, 14348 KB] Evaluated 11 state(s).
[t=0.00425526s, 14348 KB] Evaluations: 22
[t=0.00425526s, 14348 KB] Generated 10 state(s).
[t=0.00425526s, 14348 KB] Dead ends: 0 state(s).
[t=0.00425526s, 14348 KB] Search time: 0.00230957s
[t=0.00425526s, 14348 KB] Total time: 0.00425526s
Solution found.
Peak memory: 14348 KB
Remove intermediate file output.sas
search exit code: 0

INFO     Planner time: 0.04s
/home/wbm3/anaconda3/envs/6484_dqn/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Box bound precision lowered by casting to float32[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
[32m[INFO][0m[2022-05-03 02:55:10]: [32mExploration steps: 10050[0m
[32m[INFO][0m[2022-05-03 02:55:10]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000010050.pt.[0m
[32m[INFO][0m[2022-05-03 02:55:10]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 02:55:10]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 02:55:10]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 02:55:37]: [32mExploration steps: 15050[0m
[32m[INFO][0m[2022-05-03 02:55:37]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000015050.pt.[0m
[32m[INFO][0m[2022-05-03 02:55:37]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 02:55:37]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 02:55:37]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 02:56:05]: [32mExploration steps: 20050[0m
[32m[INFO][0m[2022-05-03 02:56:05]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000020050.pt.[0m
[32m[INFO][0m[2022-05-03 02:56:05]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 02:56:05]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 02:56:06]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 02:56:34]: [32mExploration steps: 25050[0m
[32m[INFO][0m[2022-05-03 02:56:34]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000025050.pt.[0m
[32m[INFO][0m[2022-05-03 02:56:34]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 02:56:34]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 02:56:34]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 02:57:02]: [32mExploration steps: 30050[0m
[32m[INFO][0m[2022-05-03 02:57:02]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000030050.pt.[0m
[32m[INFO][0m[2022-05-03 02:57:02]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 02:57:02]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 02:57:03]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 02:57:31]: [32mExploration steps: 35050[0m
[32m[INFO][0m[2022-05-03 02:57:31]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000035050.pt.[0m
[32m[INFO][0m[2022-05-03 02:57:31]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 02:57:31]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 02:57:31]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 02:57:59]: [32mExploration steps: 40050[0m
[32m[INFO][0m[2022-05-03 02:57:59]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000040050.pt.[0m
[32m[INFO][0m[2022-05-03 02:57:59]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 02:57:59]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 02:57:59]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 02:58:27]: [32mExploration steps: 45050[0m
[32m[INFO][0m[2022-05-03 02:58:27]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000045050.pt.[0m
[32m[INFO][0m[2022-05-03 02:58:27]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 02:58:27]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 02:58:27]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 02:58:55]: [32mExploration steps: 50050[0m
[32m[INFO][0m[2022-05-03 02:58:55]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000050050.pt.[0m
[32m[INFO][0m[2022-05-03 02:58:55]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 02:58:56]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 02:59:24]: [32mExploration steps: 55050[0m
[32m[INFO][0m[2022-05-03 02:59:24]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000055050.pt.[0m
[32m[INFO][0m[2022-05-03 02:59:24]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 02:59:24]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 02:59:24]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 02:59:52]: [32mExploration steps: 60050[0m
[32m[INFO][0m[2022-05-03 02:59:52]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000060050.pt.[0m
[32m[INFO][0m[2022-05-03 02:59:52]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 02:59:52]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 02:59:53]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:00:21]: [32mExploration steps: 65050[0m
[32m[INFO][0m[2022-05-03 03:00:21]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000065050.pt.[0m
[32m[INFO][0m[2022-05-03 03:00:21]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:00:21]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:00:22]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:00:50]: [32mExploration steps: 70050[0m
[32m[INFO][0m[2022-05-03 03:00:50]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000070050.pt.[0m
[32m[INFO][0m[2022-05-03 03:00:50]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:00:50]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:00:51]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:01:19]: [32mExploration steps: 75050[0m
[32m[INFO][0m[2022-05-03 03:01:19]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000075050.pt.[0m
[32m[INFO][0m[2022-05-03 03:01:19]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:01:19]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:01:19]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:01:48]: [32mExploration steps: 80050[0m
[32m[INFO][0m[2022-05-03 03:01:48]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000080050.pt.[0m
[32m[INFO][0m[2022-05-03 03:01:48]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:01:48]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:01:48]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:02:16]: [32mExploration steps: 85050[0m
[32m[INFO][0m[2022-05-03 03:02:16]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000085050.pt.[0m
[32m[INFO][0m[2022-05-03 03:02:16]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:02:16]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:02:17]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:02:46]: [32mExploration steps: 90050[0m
[32m[INFO][0m[2022-05-03 03:02:46]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000090050.pt.[0m
[32m[INFO][0m[2022-05-03 03:02:46]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:02:46]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:02:46]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:03:14]: [32mExploration steps: 95050[0m
[32m[INFO][0m[2022-05-03 03:03:14]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000095050.pt.[0m
[32m[INFO][0m[2022-05-03 03:03:14]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:03:15]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:03:44]: [32mExploration steps: 100050[0m
[32m[INFO][0m[2022-05-03 03:03:44]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000100050.pt.[0m
[32m[INFO][0m[2022-05-03 03:03:44]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:03:44]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:04:13]: [32mExploration steps: 105050[0m
[32m[INFO][0m[2022-05-03 03:04:13]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000105050.pt.[0m
[32m[INFO][0m[2022-05-03 03:04:13]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:04:13]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:04:14]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:04:42]: [32mExploration steps: 110050[0m
[32m[INFO][0m[2022-05-03 03:04:42]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000110050.pt.[0m
[32m[INFO][0m[2022-05-03 03:04:42]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:04:42]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:04:43]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:05:11]: [32mExploration steps: 115050[0m
[32m[INFO][0m[2022-05-03 03:05:11]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000115050.pt.[0m
[32m[INFO][0m[2022-05-03 03:05:11]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:05:11]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:05:12]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:05:40]: [32mExploration steps: 120050[0m
[32m[INFO][0m[2022-05-03 03:05:40]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000120050.pt.[0m
[32m[INFO][0m[2022-05-03 03:05:40]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:05:40]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:05:42]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:06:10]: [32mExploration steps: 125050[0m
[32m[INFO][0m[2022-05-03 03:06:10]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000125050.pt.[0m
[32m[INFO][0m[2022-05-03 03:06:10]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:06:10]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:06:11]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:06:39]: [32mExploration steps: 130050[0m
[32m[INFO][0m[2022-05-03 03:06:39]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000130050.pt.[0m
[32m[INFO][0m[2022-05-03 03:06:39]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:06:39]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:06:40]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:07:09]: [32mExploration steps: 135050[0m
[32m[INFO][0m[2022-05-03 03:07:09]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000135050.pt.[0m
[32m[INFO][0m[2022-05-03 03:07:09]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:07:09]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:07:10]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:07:38]: [32mExploration steps: 140050[0m
[32m[INFO][0m[2022-05-03 03:07:38]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000140050.pt.[0m
[32m[INFO][0m[2022-05-03 03:07:38]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:07:38]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:07:40]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:08:08]: [32mExploration steps: 145050[0m
[32m[INFO][0m[2022-05-03 03:08:08]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000145050.pt.[0m
[32m[INFO][0m[2022-05-03 03:08:08]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:08:08]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:08:09]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:08:37]: [32mExploration steps: 150050[0m
[32m[INFO][0m[2022-05-03 03:08:37]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000150050.pt.[0m
[32m[INFO][0m[2022-05-03 03:08:37]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:08:39]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:09:07]: [32mExploration steps: 155050[0m
[32m[INFO][0m[2022-05-03 03:09:07]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000155050.pt.[0m
[32m[INFO][0m[2022-05-03 03:09:07]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:09:09]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:09:37]: [32mExploration steps: 160050[0m
[32m[INFO][0m[2022-05-03 03:09:37]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000160050.pt.[0m
[32m[INFO][0m[2022-05-03 03:09:37]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:09:39]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:10:07]: [32mExploration steps: 165050[0m
[32m[INFO][0m[2022-05-03 03:10:07]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000165050.pt.[0m
[32m[INFO][0m[2022-05-03 03:10:07]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:10:08]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:10:36]: [32mExploration steps: 170050[0m
[32m[INFO][0m[2022-05-03 03:10:36]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000170050.pt.[0m
[32m[INFO][0m[2022-05-03 03:10:36]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:10:38]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:11:06]: [32mExploration steps: 175050[0m
[32m[INFO][0m[2022-05-03 03:11:06]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000175050.pt.[0m
[32m[INFO][0m[2022-05-03 03:11:06]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:11:06]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:11:07]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:11:35]: [32mExploration steps: 180050[0m
[32m[INFO][0m[2022-05-03 03:11:35]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000180050.pt.[0m
[32m[INFO][0m[2022-05-03 03:11:35]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt.[0m
[32m[INFO][0m[2022-05-03 03:11:35]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:11:37]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:12:05]: [32mExploration steps: 185050[0m
[32m[INFO][0m[2022-05-03 03:12:05]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000185050.pt.[0m
[32m[INFO][0m[2022-05-03 03:12:05]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:12:07]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:12:34]: [32mExploration steps: 190050[0m
[32m[INFO][0m[2022-05-03 03:12:34]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000190050.pt.[0m
[32m[INFO][0m[2022-05-03 03:12:34]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:12:36]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:13:05]: [32mExploration steps: 195050[0m
[32m[INFO][0m[2022-05-03 03:13:05]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000195050.pt.[0m
[32m[INFO][0m[2022-05-03 03:13:05]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:13:07]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:13:35]: [32mExploration steps: 200050[0m
[32m[INFO][0m[2022-05-03 03:13:35]: [32mSaving checkpoint: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/ckpt_000000200050.pt.[0m
[32m[INFO][0m[2022-05-03 03:13:35]: [32mSaving the replay buffer to: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
[32m[INFO][0m[2022-05-03 03:13:37]: [32mThe replay buffer is saved.[0m
[32m[INFO][0m[2022-05-03 03:13:37]: [32mLoading model from /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/model_best.pt[0m
[32m[INFO][0m[2022-05-03 03:13:37]: [32mLoading the replay buffer from: /home/wbm3/Documents/GitHub/airobot_reward_densification/data/URReacher-v1_reach_dense_handcrafted_sac/seed_0/model/mem.pkl.[0m
====================================
      Device:cuda
      Total number of steps:200000
====================================
INFO: Making new env: URReacher-v1 ({'reward_type': 'dense_handcrafted', 'gui': False, 'with_obstacle': True, 'max_episode_length': 50})
================================================
With obstacle in the scene:True
================================================
{'eval/episode_length/max': 50,
 'eval/episode_length/mean': 50.0,
 'eval/episode_length/median': 50.0,
 'eval/episode_length/min': 50,
 'eval/return/max': -39.115047,
 'eval/return/mean': -39.115047,
 'eval/return/median': -39.115047,
 'eval/return/min': -39.115047,
 'eval/smooth_return/mean': -38.84417848763956}
ven = NVIDIA Corporation
ven = NVIDIA Corporation
Destroy EGL OpenGL window.
